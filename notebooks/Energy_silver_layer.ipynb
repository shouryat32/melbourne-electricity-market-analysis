{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1cb09e1-0337-47fa-aef6-93f036594481",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import (\n",
    "    col, lit, coalesce, \n",
    "    round as spark_round,\n",
    "    avg as spark_avg,\n",
    "    when, hour, date_format\n",
    ")\n",
    "from datetime import datetime\n",
    "\n",
    "spark.sql(\"USE energy_analytics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13ef6179-1894-4693-a56d-f9bfe9bec576",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Combine Historical + Live Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fabc79f8-c9fc-482d-b4cf-8a2726ff9223",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDCC5 Last price timestamp: 2026-02-20 16:35:52.630667\n✅ Live new:       0\n✅ Historical new: 0\n✅ Total new:      0\n⏭️  No new records to append\n+------+-------------+---------------+-----+---------+---------+------------+------+----------+\n|region|datetime_aest|settlement_date|price|raise_reg|lower_reg|total_demand|source|price_tier|\n+------+-------------+---------------+-----+---------+---------+------------+------+----------+\n+------+-------------+---------------+-----+---------+---------+------------+------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "try:\n",
    "    last_prices_ts = spark.sql(\"SELECT MAX(datetime_aest) as last_ts FROM silver_prices\").collect()[0]['last_ts']\n",
    "    if last_prices_ts is None:\n",
    "        last_prices_ts = '2025-01-01 00:00:00'\n",
    "    print(f\"\uD83D\uDCC5 Last price timestamp: {last_prices_ts}\")\n",
    "except:\n",
    "    last_prices_ts = '2025-01-01 00:00:00'\n",
    "    print(f\"⚠️  silver_prices doesn't exist yet, processing all data\")\n",
    "\n",
    "# Live prices - only NEW records\n",
    "df_live_prices = spark.table(\"bronze_aemo_live_prices\") \\\n",
    "    .filter(col(\"settlement_datetime_aest\") > last_prices_ts) \\\n",
    "    .select(\n",
    "        col(\"region\"),\n",
    "        col(\"settlement_datetime_aest\").alias(\"datetime_aest\"),\n",
    "        col(\"settlement_date\"),\n",
    "        col(\"price\"),\n",
    "        col(\"raise_reg\"),\n",
    "        col(\"lower_reg\"),\n",
    "        lit(None).cast(\"double\").alias(\"total_demand\"),\n",
    "        col(\"source\")\n",
    "    )\n",
    "\n",
    "# Historical prices - only NEW records\n",
    "df_hist_prices = spark.table(\"bronze_aemo_historical_prices\") \\\n",
    "    .filter(col(\"settlement_datetime_aest\") > last_prices_ts) \\\n",
    "    .select(\n",
    "        col(\"region\"),\n",
    "        col(\"settlement_datetime_aest\").alias(\"datetime_aest\"),\n",
    "        col(\"settlement_date\"),\n",
    "        col(\"price\"),\n",
    "        lit(None).cast(\"double\").alias(\"raise_reg\"),\n",
    "        lit(None).cast(\"double\").alias(\"lower_reg\"),\n",
    "        col(\"total_demand\"),\n",
    "        col(\"source\")\n",
    "    )\n",
    "\n",
    "\n",
    "df_prices_all = df_live_prices.union(df_hist_prices)\n",
    "\n",
    "\n",
    "df_prices_all = df_prices_all.withColumn(\"price_tier\", \n",
    "    when(col(\"price\") < 0, \"negative\")\n",
    "    .when(col(\"price\") < 50, \"cheap\")\n",
    "    .when(col(\"price\") < 100, \"normal\")\n",
    "    .when(col(\"price\") < 300, \"expensive\")\n",
    "    .otherwise(\"spike\")\n",
    ")\n",
    "\n",
    "print(f\"✅ Live new:       {df_live_prices.count()}\")\n",
    "print(f\"✅ Historical new: {df_hist_prices.count()}\")\n",
    "print(f\"✅ Total new:      {df_prices_all.count()}\")\n",
    "\n",
    "if df_prices_all.count() > 0:\n",
    "    \n",
    "    df_prices_all.dropDuplicates([\"region\", \"datetime_aest\"]) \\\n",
    "        .write.format(\"delta\") \\\n",
    "        .mode(\"append\") \\\n",
    "        .partitionBy(\"settlement_date\", \"region\") \\\n",
    "        .saveAsTable(\"silver_prices\")\n",
    "    print(\"✅ Appended to silver_prices\")\n",
    "else:\n",
    "    print(\"⏭️  No new records to append\")\n",
    "\n",
    "df_prices_all.orderBy(\"datetime_aest\", \"region\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4bd3edc3-f279-4caf-9d41-6ed8fda0e7e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDCC5 Last generation timestamp: 2026-02-20 16:35:52.630667\n✅ Live new:       0\n✅ Historical new: 0\n✅ Total new:      0\n⏭️  No new records to append\n+------+-------------+---------------+--------------------+------------------------+------------+---------------+-----------+------+----------------+-------------+\n|region|datetime_aest|settlement_date|scheduled_generation|semischeduled_generation|total_demand|net_interchange|battery_mwh|source|total_generation|renewable_pct|\n+------+-------------+---------------+--------------------+------------------------+------------+---------------+-----------+------+----------------+-------------+\n+------+-------------+---------------+--------------------+------------------------+------------+---------------+-----------+------+----------------+-------------+\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get last processed timestamp\n",
    "try:\n",
    "    last_gen_ts = spark.sql(\"SELECT MAX(datetime_aest) as last_ts FROM silver_generation\").collect()[0]['last_ts']\n",
    "    if last_gen_ts is None:\n",
    "        last_gen_ts = '2025-01-01 00:00:00'\n",
    "    print(f\"\uD83D\uDCC5 Last generation timestamp: {last_gen_ts}\")\n",
    "except:\n",
    "    last_gen_ts = '2025-01-01 00:00:00'\n",
    "    print(f\"⚠️  silver_generation doesn't exist yet, processing all data\")\n",
    "\n",
    "\n",
    "df_live_gen = spark.table(\"bronze_aemo_generation\") \\\n",
    "    .filter(col(\"settlement_datetime_aest\") > last_gen_ts) \\\n",
    "    .select(\n",
    "        col(\"region\"),\n",
    "        col(\"settlement_datetime_aest\").alias(\"datetime_aest\"),\n",
    "        col(\"settlement_date\"),\n",
    "        col(\"scheduled_generation\"),\n",
    "        col(\"semischeduled_generation\"),\n",
    "        col(\"total_demand\"),\n",
    "        col(\"net_interchange\"),\n",
    "        lit(None).cast(\"double\").alias(\"battery_mwh\"),\n",
    "        col(\"source\")\n",
    "    )\n",
    "\n",
    "\n",
    "df_hist_gen = spark.table(\"bronze_aemo_historical_generation\") \\\n",
    "    .filter(col(\"interval_datetime\") > last_gen_ts) \\\n",
    "    .select(\n",
    "        col(\"region\"),\n",
    "        col(\"interval_datetime\").alias(\"datetime_aest\"),\n",
    "        col(\"settlement_date\"),\n",
    "        col(\"scheduled_generation\"),\n",
    "        col(\"semischeduled_generation\"),\n",
    "        col(\"total_demand\"),\n",
    "        lit(None).cast(\"double\").alias(\"net_interchange\"),\n",
    "        col(\"battery_mwh\"),\n",
    "        col(\"source\")\n",
    "    )\n",
    "\n",
    "# Union\n",
    "df_gen_all = df_live_gen.union(df_hist_gen)\n",
    "\n",
    "# Add calculated columns\n",
    "df_gen_all = df_gen_all \\\n",
    "    .withColumn(\"total_generation\", \n",
    "        col(\"scheduled_generation\") + col(\"semischeduled_generation\")\n",
    "    ) \\\n",
    "    .withColumn(\"renewable_pct\",\n",
    "        spark_round((col(\"semischeduled_generation\") / col(\"total_generation\")) * 100, 1)\n",
    "    )\n",
    "\n",
    "print(f\"✅ Live new:       {df_live_gen.count()}\")\n",
    "print(f\"✅ Historical new: {df_hist_gen.count()}\")\n",
    "print(f\"✅ Total new:      {df_gen_all.count()}\")\n",
    "\n",
    "if df_gen_all.count() > 0:\n",
    "    df_gen_all.dropDuplicates([\"region\", \"datetime_aest\"]) \\\n",
    "        .write.format(\"delta\") \\\n",
    "        .mode(\"append\") \\\n",
    "        .partitionBy(\"settlement_date\", \"region\") \\\n",
    "        .saveAsTable(\"silver_generation\")\n",
    "    print(\"✅ Appended to silver_generation\")\n",
    "else:\n",
    "    print(\"⏭️  No new records to append\")\n",
    "\n",
    "df_gen_all.orderBy(\"datetime_aest\", \"region\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1c9bb49-6199-411d-8fe3-90873e2d1d49",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDCC5 Last weather timestamp: 2026-02-20 23:00:00\n✅ Live new:       0\n✅ Historical new: 0\n✅ Total new:      0\n⏭️  No new records to append\n+-------------+---------------+--------+-----------------+------------+--------------+-------------------+\n|datetime_aest|settlement_date|avg_temp|avg_apparent_temp|avg_humidity|avg_wind_speed|total_precipitation|\n+-------------+---------------+--------+-----------------+------------+--------------+-------------------+\n+-------------+---------------+--------+-----------------+------------+--------------+-------------------+\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Get last processed timestamp\n",
    "try:\n",
    "    last_weather_ts = spark.sql(\"SELECT MAX(datetime_aest) as last_ts FROM silver_weather\").collect()[0]['last_ts']\n",
    "    if last_weather_ts is None:\n",
    "        last_weather_ts = '2025-01-01 00:00:00'\n",
    "    print(f\"\uD83D\uDCC5 Last weather timestamp: {last_weather_ts}\")\n",
    "except:\n",
    "    last_weather_ts = '2025-01-01 00:00:00'\n",
    "    print(f\"⚠️  silver_weather doesn't exist yet, processing all data\")\n",
    "\n",
    "# Live weather - only NEW records\n",
    "df_live_weather = spark.table(\"bronze_bom_weather\") \\\n",
    "    .filter(col(\"observation_datetime_aest\") > last_weather_ts) \\\n",
    "    .select(\n",
    "        col(\"observation_datetime_aest\").alias(\"datetime_aest\"),\n",
    "        col(\"settlement_date\"),\n",
    "        col(\"station_id\"),\n",
    "        col(\"station_name\"),\n",
    "        col(\"air_temp\"),\n",
    "        col(\"apparent_temp\"),\n",
    "        col(\"relative_humidity\"),\n",
    "        col(\"wind_speed_kmh\").cast(\"double\"),\n",
    "        lit(None).cast(\"double\").alias(\"precipitation\"),\n",
    "        col(\"source\")\n",
    "    )\n",
    "\n",
    "# Historical weather - only NEW records\n",
    "df_hist_weather = spark.table(\"bronze_historical_weather\") \\\n",
    "    .filter(col(\"observation_datetime_aest\") > last_weather_ts) \\\n",
    "    .select(\n",
    "        col(\"observation_datetime_aest\").alias(\"datetime_aest\"),\n",
    "        col(\"settlement_date\"),\n",
    "        col(\"station_id\"),\n",
    "        col(\"station_name\"),\n",
    "        col(\"air_temp\"),\n",
    "        col(\"apparent_temp\"),\n",
    "        col(\"relative_humidity\"),\n",
    "        col(\"wind_speed_kmh\"),\n",
    "        col(\"precipitation\"),\n",
    "        col(\"source\")\n",
    "    )\n",
    "\n",
    "\n",
    "df_weather_all = df_live_weather.union(df_hist_weather)\n",
    "\n",
    "# Average across stations per timestamp\n",
    "df_weather_clean = df_weather_all \\\n",
    "    .groupBy(\"datetime_aest\", \"settlement_date\") \\\n",
    "    .agg(\n",
    "        spark_avg(\"air_temp\").alias(\"avg_temp\"),\n",
    "        spark_avg(\"apparent_temp\").alias(\"avg_apparent_temp\"),\n",
    "        spark_avg(\"relative_humidity\").alias(\"avg_humidity\"),\n",
    "        spark_avg(\"wind_speed_kmh\").alias(\"avg_wind_speed\"),\n",
    "        spark_avg(\"precipitation\").alias(\"total_precipitation\")\n",
    "    ) \\\n",
    "    .withColumn(\"avg_temp\", spark_round(col(\"avg_temp\"), 1)) \\\n",
    "    .withColumn(\"avg_apparent_temp\", spark_round(col(\"avg_apparent_temp\"), 1))\n",
    "\n",
    "print(f\"✅ Live new:       {df_live_weather.count()}\")\n",
    "print(f\"✅ Historical new: {df_hist_weather.count()}\")\n",
    "print(f\"✅ Total new:      {df_weather_clean.count()}\")\n",
    "\n",
    "if df_weather_clean.count() > 0:\n",
    "    df_weather_clean.dropDuplicates([\"datetime_aest\"]) \\\n",
    "        .write.format(\"delta\") \\\n",
    "        .mode(\"append\") \\\n",
    "        .partitionBy(\"settlement_date\") \\\n",
    "        .saveAsTable(\"silver_weather\")\n",
    "    print(\"✅ Appended to silver_weather\")\n",
    "else:\n",
    "    print(\"⏭️  No new records to append\")\n",
    "\n",
    "df_weather_clean.orderBy(\"datetime_aest\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b68350e-824e-4be6-b437-d7689b73b967",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#CELL 5: Save Unified Tables & Add Calculated Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2f35dd6-9cad-4650-ab4c-da144c1c2296",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved silver_prices: 0 records\n✅ Saved silver_generation: 0 records\n✅ Saved silver_weather: 0 records\n\n\uD83D\uDCCA Sample data:\n+------+-------------+---------------+-----+---------+---------+------------+------+----------+\n|region|datetime_aest|settlement_date|price|raise_reg|lower_reg|total_demand|source|price_tier|\n+------+-------------+---------------+-----+---------+---------+------------+------+----------+\n+------+-------------+---------------+-----+---------+---------+------------+------+----------+\n\n+------+-------------+---------------+--------------------+------------------------+------------+---------------+-----------+------+----------------+-------------+\n|region|datetime_aest|settlement_date|scheduled_generation|semischeduled_generation|total_demand|net_interchange|battery_mwh|source|total_generation|renewable_pct|\n+------+-------------+---------------+--------------------+------------------------+------------+---------------+-----------+------+----------------+-------------+\n+------+-------------+---------------+--------------------+------------------------+------------+---------------+-----------+------+----------------+-------------+\n\n+-------------+---------------+--------+-----------------+------------+--------------+-------------------+\n|datetime_aest|settlement_date|avg_temp|avg_apparent_temp|avg_humidity|avg_wind_speed|total_precipitation|\n+-------------+---------------+--------+-----------------+------------+--------------+-------------------+\n+-------------+---------------+--------+-----------------+------------+--------------+-------------------+\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from pyspark.sql.functions import round as spark_round, when, hour\n",
    "\n",
    "df_prices_clean = df_prices_all \\\n",
    "    .withColumn(\"price_tier\", \n",
    "        when(col(\"price\") < 0, \"negative\")\n",
    "        .when(col(\"price\") < 50, \"cheap\")\n",
    "        .when(col(\"price\") < 100, \"normal\")\n",
    "        .when(col(\"price\") < 300, \"expensive\")\n",
    "        .otherwise(\"spike\")\n",
    "    ) \\\n",
    "    .dropDuplicates([\"region\", \"datetime_aest\"]) \n",
    "\n",
    "df_prices_clean.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .partitionBy(\"settlement_date\", \"region\") \\\n",
    "    .saveAsTable(\"energy_analytics.silver_prices\")\n",
    "\n",
    "print(f\"✅ Saved silver_prices: {df_prices_clean.count()} records\")\n",
    "\n",
    "\n",
    "df_gen_clean = df_gen_all \\\n",
    "    .withColumn(\"total_generation\", \n",
    "        col(\"scheduled_generation\") + col(\"semischeduled_generation\")\n",
    "    ) \\\n",
    "    .withColumn(\"renewable_pct\",\n",
    "        spark_round((col(\"semischeduled_generation\") / col(\"total_generation\")) * 100, 1)\n",
    "    ) \\\n",
    "    .dropDuplicates([\"region\", \"datetime_aest\"])\n",
    "\n",
    "df_gen_clean.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .partitionBy(\"settlement_date\", \"region\") \\\n",
    "    .saveAsTable(\"energy_analytics.silver_generation\")\n",
    "\n",
    "print(f\"✅ Saved silver_generation: {df_gen_clean.count()} records\")\n",
    "\n",
    "\n",
    "df_weather_clean = df_weather_all \\\n",
    "    .groupBy(\"datetime_aest\", \"settlement_date\") \\\n",
    "    .agg(\n",
    "        spark_avg(\"air_temp\").alias(\"avg_temp\"),\n",
    "        spark_avg(\"apparent_temp\").alias(\"avg_apparent_temp\"),\n",
    "        spark_avg(\"relative_humidity\").alias(\"avg_humidity\"),\n",
    "        spark_avg(\"wind_speed_kmh\").alias(\"avg_wind_speed\"),\n",
    "        spark_avg(\"precipitation\").alias(\"total_precipitation\")\n",
    "    ) \\\n",
    "    .withColumn(\"avg_temp\", spark_round(col(\"avg_temp\"), 1)) \\\n",
    "    .withColumn(\"avg_apparent_temp\", spark_round(col(\"avg_apparent_temp\"), 1))\n",
    "\n",
    "df_weather_clean.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .partitionBy(\"settlement_date\") \\\n",
    "    .saveAsTable(\"energy_analytics.silver_weather\")\n",
    "\n",
    "print(f\"✅ Saved silver_weather: {df_weather_clean.count()} records\")\n",
    "\n",
    "\n",
    "print(\"\\n\uD83D\uDCCA Sample data:\")\n",
    "df_prices_clean.filter(col(\"region\") == \"VIC1\").orderBy(\"datetime_aest\").show(3)\n",
    "df_gen_clean.filter(col(\"region\") == \"VIC1\").orderBy(\"datetime_aest\").show(3)\n",
    "df_weather_clean.orderBy(\"datetime_aest\").show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "182cfc7e-07ad-44c9-bfc5-a4326b000a3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# CELL 6: Create Final Unified Silver Table VIC1 - Melbourne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd47c629-5578-47af-80ab-e37c096b77b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDCC5 Last Melbourne timestamp: 2026-02-20 16:35:52.630667\n✅ New records to add: 0\n⏭️  No new records to append\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    last_melb_ts = spark.sql(\"SELECT MAX(datetime_aest) as last_ts FROM silver_energy_melbourne\").collect()[0]['last_ts']\n",
    "    if last_melb_ts is None:\n",
    "        last_melb_ts = '2025-01-01 00:00:00'\n",
    "    print(f\"\uD83D\uDCC5 Last Melbourne timestamp: {last_melb_ts}\")\n",
    "except:\n",
    "    last_melb_ts = '2025-01-01 00:00:00'\n",
    "    print(f\"⚠️  silver_energy_melbourne doesn't exist yet, processing all data\")\n",
    "\n",
    "\n",
    "df_prices_vic = spark.table(\"silver_prices\") \\\n",
    "    .filter(col(\"region\") == \"VIC1\") \\\n",
    "    .filter(col(\"datetime_aest\") > last_melb_ts) \\\n",
    "    .alias(\"p\")\n",
    "\n",
    "df_gen_vic = spark.table(\"silver_generation\") \\\n",
    "    .filter(col(\"region\") == \"VIC1\") \\\n",
    "    .filter(col(\"datetime_aest\") > last_melb_ts) \\\n",
    "    .alias(\"g\")\n",
    "\n",
    "df_weather = spark.table(\"silver_weather\") \\\n",
    "    .filter(col(\"datetime_aest\") > last_melb_ts) \\\n",
    "    .alias(\"w\")\n",
    "\n",
    "\n",
    "df_silver_energy = df_prices_vic \\\n",
    "    .join(df_gen_vic, \n",
    "          (col(\"p.datetime_aest\") == col(\"g.datetime_aest\")) & \n",
    "          (col(\"p.settlement_date\") == col(\"g.settlement_date\")), \n",
    "          \"left\") \\\n",
    "    .join(df_weather, \n",
    "          (col(\"p.datetime_aest\") == col(\"w.datetime_aest\")) & \n",
    "          (col(\"p.settlement_date\") == col(\"w.settlement_date\")), \n",
    "          \"left\") \\\n",
    "    .select(\n",
    "        lit(\"VIC1\").alias(\"region_code\"),\n",
    "        lit(\"Victoria (Melbourne)\").alias(\"region_name\"),\n",
    "        col(\"p.datetime_aest\"),\n",
    "        col(\"p.settlement_date\"),\n",
    "        hour(\"p.datetime_aest\").alias(\"hour_of_day\"),\n",
    "        col(\"p.price\"),\n",
    "        col(\"p.price_tier\"),\n",
    "        coalesce(col(\"g.total_demand\"), col(\"p.total_demand\")).alias(\"demand_mw\"),\n",
    "        col(\"g.scheduled_generation\"),\n",
    "        col(\"g.semischeduled_generation\"),\n",
    "        col(\"g.total_generation\"),\n",
    "        col(\"g.renewable_pct\"),\n",
    "        col(\"g.battery_mwh\"),\n",
    "        col(\"w.avg_temp\"),\n",
    "        col(\"w.avg_apparent_temp\"),\n",
    "        col(\"w.avg_humidity\"),\n",
    "        col(\"w.avg_wind_speed\"),\n",
    "        col(\"w.total_precipitation\")\n",
    "    ) \\\n",
    "    .withColumn(\"is_peak\", \n",
    "        when((col(\"hour_of_day\").between(7, 9)) | (col(\"hour_of_day\").between(17, 20)), True)\n",
    "        .otherwise(False)\n",
    "    )\n",
    "\n",
    "print(f\"✅ New records to add: {df_silver_energy.count()}\")\n",
    "\n",
    "if df_silver_energy.count() > 0:\n",
    "    df_silver_energy.dropDuplicates([\"datetime_aest\"]) \\\n",
    "        .write.format(\"delta\") \\\n",
    "        .mode(\"append\") \\\n",
    "        .partitionBy(\"settlement_date\") \\\n",
    "        .saveAsTable(\"silver_energy_melbourne\")\n",
    "    print(\"✅ Appended to silver_energy_melbourne\")\n",
    "    df_silver_energy.orderBy(\"datetime_aest\").show(5, truncate=False)\n",
    "else:\n",
    "    print(\"⏭️  No new records to append\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Energy_silver_layer",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}